# generate_deepseek.py
import json, os, re
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
import torch

# =====================
# PARAMETERS
# =====================
MODEL_PATH = "deepseek-ai/deepseek-coder-1.3b-instruct"

PROMPTS = {
    "CGCS": """You are an expert Python developer. Solve the problem using a Constraint-Guided Code Synthesis approach.

Problem:
{problem}

Instructions:
1. List all constraints and edge cases that must be handled.
2. For each code block you write, tag it with the constraints it satisfies.
3. After each block, reason through an example to verify correctness.
4. Only produce final code after all constraints are verified.
5. Provide clean, commented Python code at the end that meets all constraints.

Example format:
# Constraint: {describe constraint}
# Code block
{code}
# Reasoning: {verify with example}
"""
}

MAX_NEW_TOKENS = 256       # handle reasoning output
TEMPERATURE = 0.2          # greedy decoding

# =====================
# UTILITIES
# =====================
def extract_code(text: str) -> str:
    """Extract the last Python code block, fix unterminated docstrings"""
    code_blocks = re.findall(r"```(?:python)?\n(.*?)```", text, re.DOTALL | re.IGNORECASE)
    if code_blocks:
        code = code_blocks[-1].strip()
        if code.count('"""') % 2 != 0:
            code += '"""'
        return code
    m = re.search(r"(def\s+[\s\S]+)", text)
    return m.group(1).strip() if m else text.strip()

def make_pipeline(model_path):
    tokenizer = AutoTokenizer.from_pretrained(model_path)
    kwargs = {"device_map": "auto"}
    if torch.cuda.is_available():
        kwargs["torch_dtype"] = torch.float16
    model = AutoModelForCausalLM.from_pretrained(model_path, **kwargs)
    pipe = pipeline("text-generation", model=model, tokenizer=tokenizer)
    return pipe

# =====================
# MAIN
# =====================
def main():
    # Load problems
    with open("humaneval_subset.json") as f:
        problems = json.load(f)

    # Only use the first 10 problems
    problems = problems[:10]

    # Initialize pipeline
    print(f"Loading model {MODEL_PATH} ...")
    pipe = make_pipeline(MODEL_PATH)

    # Generate code using CGCS
    strategy = "CGCS"
    template = PROMPTS[strategy]
    outdir = f"outputs/deepseek_{strategy}"
    os.makedirs(outdir, exist_ok=True)
    print(f"\n=== Generating for DeepSeek | {strategy} -> {outdir} ===")

    for idx, prob in enumerate(tqdm(problems)):
        prompt = template.format(problem=prob["prompt"])
        try:
            res = pipe(
                prompt,
                max_new_tokens=MAX_NEW_TOKENS,
                temperature=TEMPERATURE,
                do_sample=False,
                num_return_sequences=1
            )[0]["generated_text"]
        except Exception as e:
            print(f"Generation error for {prob.get('id','?')}: {e}")
            res = ""

        code = extract_code(res)
        
        # Check syntax
        try:
            compile(code, "<string>", "exec")
        except SyntaxError as e:
            print(f"Syntax error in {prob.get('id','?')}: {e}")
            code = "# Failed to generate valid Python code"

        safe_id = prob.get("id", prob.get("task_id", f"prob_{idx}"))
        fname = os.path.join(outdir, f"{safe_id}.py")
        with open(fname, "w") as f:
            f.write(f"# Generated by model: DeepSeek\n# Strategy: {strategy}\n\n")
            f.write(code)

    print("\nFull generation finished.")

if __name__ == "__main__":
    main()
